{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Energy Prediction Dataset: Raw and Preprocessed Data\n",
    "## A Complete Machine Learning Dataset for Solar Power Forecasting\n",
    "\n",
    "This notebook contains comprehensive datasets for solar energy prediction using machine learning. It includes both raw data with real-world issues and preprocessed data ready for model training.\n",
    "\n",
    "### Dataset Overview:\n",
    "- **Time Period**: January 1 - December 31, 2023\n",
    "- **Temporal Resolution**: Hourly data (8,760 records)\n",
    "- **Target Variable**: Solar Power Output (W/m²)\n",
    "- **Features**: 9 meteorological and solar radiation parameters\n",
    "- **Use Case**: Solar energy generation forecasting and renewable energy planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load raw dataset\n",
    "raw_data = pd.read_csv('solar_energy_raw.csv')\n",
    "print('Raw Dataset Shape:', raw_data.shape)\n",
    "print('\\nFirst few rows of raw data:')\n",
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Exploration and Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== RAW DATA QUALITY ASSESSMENT ===\\n')\n",
    "\n",
    "# Missing values\n",
    "print('Missing Values:')\n",
    "print(raw_data.isnull().sum())\n",
    "print('\\nPercentage of Missing Data:')\n",
    "print((raw_data.isnull().sum() / len(raw_data)) * 100)\n",
    "\n",
    "# Statistical summary\n",
    "print('\\n=== DESCRIPTIVE STATISTICS ===')\n",
    "print(raw_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Outliers and Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR method\n",
    "def identify_outliers(data, column, multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    return (data[column] < lower_bound) | (data[column] > upper_bound)\n",
    "\n",
    "print('Outliers detected in raw data:')\n",
    "for column in ['Temperature_C', 'Humidity_%', 'Pressure_hPa', 'Wind_Speed_ms']:\n",
    "    outlier_count = identify_outliers(raw_data, column).sum()\n",
    "    print(f'{column}: {outlier_count} outliers ({(outlier_count/len(raw_data))*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Explore Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "preprocessed_data = pd.read_csv('solar_energy_preprocessed.csv')\n",
    "preprocessed_data['Timestamp'] = pd.to_datetime(preprocessed_data['Timestamp'])\n",
    "\n",
    "print('Preprocessed Dataset Shape:', preprocessed_data.shape)\n",
    "print('\\nFirst few rows of preprocessed data:')\n",
    "print(preprocessed_data.head())\n",
    "\n",
    "print('\\nFeatures in Preprocessed Data:')\n",
    "print(preprocessed_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing Pipeline Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== DATA PREPROCESSING PIPELINE ===\\n')\n",
    "\n",
    "print('Step 1: Missing Value Imputation')\n",
    "print('  - Forward fill for temporal continuity')\n",
    "print('  - Linear interpolation for smooth transitions')\n",
    "print('  - Method chosen based on time-series nature of data\\n')\n",
    "\n",
    "print('Step 2: Outlier Detection and Treatment')\n",
    "print('  - IQR-based outlier detection (Q1 - 1.5*IQR, Q3 + 1.5*IQR)')\n",
    "print('  - Replace outliers with median values')\n",
    "print('  - Prevents extreme values from distorting model training\\n')\n",
    "\n",
    "print('Step 3: Feature Engineering')\n",
    "print('  A. Temporal Features:')\n",
    "print('     - Hour, Day of Week, Month, Quarter, Day of Year')\n",
    "print('  B. Cyclical Encoding (Sine-Cosine transformation):')\n",
    "print('     - Hour_sin, Hour_cos (24-hour cycle)')\n",
    "print('     - Month_sin, Month_cos (12-month cycle)')\n",
    "print('     - DayOfYear_sin, DayOfYear_cos (365-day cycle)')\n",
    "print('  C. Lag Features:')\n",
    "print('     - Solar_Power_Lag1/3/24 (previous hour, 3 hours, 24 hours)')\n",
    "print('     - Temperature_Lag1, Irradiance_Lag1')\n",
    "print('  D. Rolling Statistics:')\n",
    "print('     - 3-hour, 6-hour, 24-hour rolling means')\n",
    "print('     - 6-hour rolling standard deviation')\n",
    "print('  E. Interaction Features:')\n",
    "print('     - Irradiance × Temperature')\n",
    "print('     - Cloud Impact Factor')\n",
    "print('  F. Derived Meteorological Features:')\n",
    "print('     - Apparent Temperature (wind chill/heat index)\\n')\n",
    "\n",
    "print('Step 4: Feature Normalization')\n",
    "print('  - StandardScaler: (x - mean) / std')\n",
    "print('  - Zero mean and unit variance for all numeric features')\n",
    "print('  - Improves model convergence and stability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering Details and Rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_text": [
    "print('=== WHY THESE FEATURES? ===\\n')\n",
    "\n",
    "print('Temporal Features:')\n",
    "print('  - Solar power generation has strong diurnal (daily) and seasonal patterns')\n",
    "print('  - Hour captures peak generation during midday')\n",
    "print('  - Month captures seasonal variation in solar intensity\\n')\n",
    "\n",
    "print('Cyclical Encoding (Sine-Cosine):')\n",
    "print('  - Standard hour encoding (0-23) treats 23 and 0 as far apart')\n",
    "print('  - Cyclical encoding captures continuity: 11 PM → 12 AM is continuous')\n",
    "print('  - Essential for time-series forecasting models\\n')\n",
    "\n",
    "print('Lag Features:')\n",
    "print('  - Solar power is autocorrelated with previous values')\n",
    "print('  - 1-hour lag: immediate persistence')\n",
    "print('  - 3-hour lag: short-term trend')\n",
    "print('  - 24-hour lag: same time yesterday (handles seasonality)\\n')\n",
    "\n",
    "print('Rolling Statistics:')\n",
    "print('  - Smooths high-frequency noise')\n",
    "print('  - Captures local trends and volatility')\n",
    "print('  - Helps model identify stability and fluctuations\\n')\n",
    "\n",
    "print('Interaction Features:')\n",
    "print('  - Solar power depends on both irradiance AND temperature')\n",
    "print('  - Cloud impact modulates theoretical generation')\n",
    "print('  - Captures non-linear relationships between variables'
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Data for Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = preprocessed_data.drop(['Timestamp', 'Solar_Power_Output_Wm2'], axis=1)\n",
    "y = preprocessed_data['Solar_Power_Output_Wm2']\n",
    "\n",
    "print(f'Features (X) shape: {X.shape}')\n",
    "print(f'Target (y) shape: {y.shape}')\n",
    "print(f'\\nNumber of features: {X.shape[1]}')\n",
    "print(f'\\nFeature list:')\n",
    "for i, col in enumerate(X.columns, 1):\n",
    "    print(f'  {i:2d}. {col}')\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'\\nTraining set size: {X_train.shape[0]} ({(X_train.shape[0]/len(X))*100:.1f}%)')\n",
    "print(f'Test set size: {X_test.shape[0]} ({(X_test.shape[0]/len(X))*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== MODEL TRAINING AND EVALUATION ===\\n')\n",
    "\n",
    "# Random Forest Model\n",
    "print('Training Random Forest Regressor...')\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "rf_train_mae = mean_absolute_error(y_train, rf_pred_train)\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_pred_test)\n",
    "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_pred_test)\n",
    "\n",
    "print(f'Random Forest Results:')\n",
    "print(f'  Training RMSE: {rf_train_rmse:.4f} W/m²')\n",
    "print(f'  Test RMSE: {rf_test_rmse:.4f} W/m²')\n",
    "print(f'  Training MAE: {rf_train_mae:.4f} W/m²')\n",
    "print(f'  Test MAE: {rf_test_mae:.4f} W/m²')\n",
    "print(f'  Training R²: {rf_train_r2:.4f}')\n",
    "print(f'  Test R²: {rf_test_r2:.4f}\\n')\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print('Top 10 Most Important Features:')\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "print('\\nTraining XGBoost Regressor...')\n",
    "xgb_model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred_train = xgb_model.predict(X_train)\n",
    "xgb_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
    "xgb_test_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred_test))\n",
    "xgb_train_mae = mean_absolute_error(y_train, xgb_pred_train)\n",
    "xgb_test_mae = mean_absolute_error(y_test, xgb_pred_test)\n",
    "xgb_train_r2 = r2_score(y_train, xgb_pred_train)\n",
    "xgb_test_r2 = r2_score(y_test, xgb_pred_test)\n",
    "\n",
    "print(f'XGBoost Results:')\n",
    "print(f'  Training RMSE: {xgb_train_rmse:.4f} W/m²')\n",
    "print(f'  Test RMSE: {xgb_test_rmse:.4f} W/m²')\n",
    "print(f'  Training MAE: {xgb_train_mae:.4f} W/m²')\n",
    "print(f'  Test MAE: {xgb_test_mae:.4f} W/m²')\n",
    "print(f'  Training R²: {xgb_train_r2:.4f}')\n",
    "print(f'  Test R²: {xgb_test_r2:.4f}')\n",
    "\n",
    "# Comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Train RMSE': [rf_train_rmse, xgb_train_rmse],\n",
    "    'Test RMSE': [rf_test_rmse, xgb_test_rmse],\n",
    "    'Train R²': [rf_train_r2, xgb_train_r2],\n",
    "    'Test R²': [rf_test_r2, xgb_test_r2]\n",
    "})\n",
    "\n",
    "print('\\n=== MODEL PERFORMANCE COMPARISON ===')\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dataset Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== DATASET QUALITY REPORT ===\\n')\n",
    "\n",
    "print('Raw Data Issues:')\n",
    "print(f'  - Missing values: {raw_data.isnull().sum().sum()} records')\n",
    "print(f'  - Outliers detected: ~{identify_outliers(raw_data, "Humidity_%").sum()} in humidity alone')\n",
    "print(f'  - Data quality: Realistic real-world noise and gaps\\n')\n",
    "\n",
    "print('Preprocessing Improvements:')\n",
    "print(f'  ✓ Missing values imputed (forward fill + interpolation)')\n",
    "print(f'  ✓ Outliers treated using IQR method')\n",
    "print(f'  ✓ Features normalized (StandardScaler)')\n",
    "print(f'  ✓ {len(X.columns)} engineered features created from original 9 features')\n",
    "print(f'  ✓ Cyclical encoding for temporal patterns')\n",
    "print(f'  ✓ Lag and rolling statistics for trend capture')\n",
    "print(f'  ✓ No missing values in final dataset\\n')\n",
    "\n",
    "print('Dataset Statistics:')\n",
    "print(f'  - Total records: {len(preprocessed_data)}')\n",
    "print(f'  - Features: {X.shape[1]}')\n",
    "print(f'  - Target variable: Solar_Power_Output_Wm2')\n",
    "print(f'  - Power output range: {y.min():.2f} to {y.max():.2f} W/m²')\n",
    "print(f'  - Mean power output: {y.mean():.2f} W/m²')\n",
    "print(f'  - Std dev: {y.std():.2f} W/m²')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Usage Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''\n=== HOW TO USE THESE DATASETS ===\n\n",
    "1. RAW DATA (solar_energy_raw.csv):\n\n",
    "   - Contains real-world data quality issues\n",
    "   - Missing values in Temperature_C (50 NaN values)\n",
    "   - Outliers in Humidity_%\n",
    "   - Use for: Learning data cleaning techniques, understanding preprocessing importance\n\n",
    "2. PREPROCESSED DATA (solar_energy_preprocessed.csv):\n\n",
    "   - Production-ready dataset\n",
    "   - All cleaning, normalization, and feature engineering applied\n",
    "   - 34 features optimized for ML models\n",
    "   - Use for: Training prediction models, machine learning projects\n\n",
    "3. RECOMMENDED ML MODELS:\n\n",
    "   - Random Forest: Good baseline, handles non-linear relationships\n",
    "   - XGBoost/LightGBM: Better performance with proper tuning\n",
    "   - LSTM/GRU: For time-series forecasting (use lag features)\n",
    "   - AutoML: For automated model selection\n\n",
    "4. EVALUATION METRICS:\n\n",
    "   - RMSE (Root Mean Squared Error): Penalizes large errors more\n",
    "   - MAE (Mean Absolute Error): Robust to outliers\n",
    "   - R² Score: Proportion of variance explained\n",
    "   - MAPE (Mean Absolute Percentage Error): For percentage-based evaluation\n\n",
    "5. NEXT STEPS:\n\n",
    "   - Experiment with feature selection\n",
    "   - Try different train-test split ratios\n",
    "   - Implement cross-validation\n",
    "   - Tune hyperparameters\n",
    "   - Deploy model for real-time predictions\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}